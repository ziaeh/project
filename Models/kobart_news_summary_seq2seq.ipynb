{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":5703,"status":"ok","timestamp":1693898641642,"user":{"displayName":"10_bagger","userId":"06014791066569861598"},"user_tz":-540},"id":"BHSZkgkt6HKp"},"outputs":[],"source":["!pip install accelerate>=0.20.1"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2109,"status":"ok","timestamp":1693898643743,"user":{"displayName":"10_bagger","userId":"06014791066569861598"},"user_tz":-540},"id":"Qj8NDzIBmfo6","outputId":"7fa8f012-0fac-4d9d-8199-9243544dcf0a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9816,"status":"ok","timestamp":1693898653556,"user":{"displayName":"10_bagger","userId":"06014791066569861598"},"user_tz":-540},"id":"aG2mAH_fm_GR","outputId":"c5e8d29d-38d5-4795-b302-14751e63d4b1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.33.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n","Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.10/dist-packages (2.0.8)\n","Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (1.23.5)\n","Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2.0.1+cu118)\n","Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.66.1)\n","Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (6.0.1)\n","Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2023.6.0)\n","Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (1.1.1)\n","Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (23.1)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.7.1)\n","Requirement already satisfied: lightning-utilities>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (0.9.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (2.31.0)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (3.8.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (3.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11.0->pytorch-lightning) (3.27.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11.0->pytorch-lightning) (16.0.6)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (3.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->pytorch-lightning) (2.1.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2023.7.22)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->pytorch-lightning) (1.3.0)\n"]}],"source":[" !pip install transformers\n"," !pip install pytorch-lightning"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":8044,"status":"ok","timestamp":1693898681860,"user":{"displayName":"10_bagger","userId":"06014791066569861598"},"user_tz":-540},"id":"YvvcXwvSKPJj"},"outputs":[],"source":["import pandas as pd\n","train_df = pd.read_csv('/content/drive/MyDrive/data/news_summary_dataset_train.tsv', sep='\\t')\n","df = train_df[:200]"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1693898681860,"user":{"displayName":"10_bagger","userId":"06014791066569861598"},"user_tz":-540},"id":"1nKDyiPO4E3d","outputId":"cf940efc-60dc-44e5-95d9-596ad6a7e958"},"outputs":[{"data":{"text/plain":["passage    0\n","summary    0\n","dtype: int64"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["df.isna().sum()"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":1426,"status":"ok","timestamp":1693898683281,"user":{"displayName":"10_bagger","userId":"06014791066569861598"},"user_tz":-540},"id":"-HxYEY-7vCCl"},"outputs":[],"source":["from transformers import AutoModelForSeq2SeqLM, AutoTokenizer"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14412,"status":"ok","timestamp":1693898697691,"user":{"displayName":"10_bagger","userId":"06014791066569861598"},"user_tz":-540},"id":"TwuD9M85nRWs","outputId":"2a275dfc-032e-4cb2-bcb6-0f567b82d04e"},"outputs":[{"name":"stderr","output_type":"stream","text":["You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"]}],"source":["import torch\n","\n","model_name = 'hyunwoongko/kobart'\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":3615,"status":"ok","timestamp":1693898701302,"user":{"displayName":"10_bagger","userId":"06014791066569861598"},"user_tz":-540},"id":"P995XaXRnB_l"},"outputs":[],"source":["input_tokenized = []\n","target_tokenized = []\n","for i in range(len(df)):\n","\n","    input_text = df.iloc[i, 0]\n","    target_text = df.iloc[i, 1]\n","\n","    input_ids = tokenizer(input_text, padding=\"max_length\", max_length=1024, truncation=True)[\"input_ids\"]\n","    target_ids = tokenizer(target_text, padding=\"max_length\", max_length=1024, truncation=True)[\"input_ids\"]\n","\n","    input_tokenized.append(input_ids)\n","    target_tokenized.append(target_ids)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":260},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1693898701303,"user":{"displayName":"10_bagger","userId":"06014791066569861598"},"user_tz":-540},"id":"xcxzxE19y5bg","outputId":"34dee280-05d5-439b-a705-4991fe022496"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'<s> 40억 달러 ‘딜’ 주인공 김봉진 우아한형제들 대표태풍 뒤의 고요함이랄까.\\n  40억 달러짜리 ‘딜’(거래)을 마친 뒤의 사무실은 조용했다.\\n  음식 배달 앱 ‘배달의민족’ 운영사 (주)우아한형제들의 서울 송파구 방이동 사옥은 비어 있었다.\\n  전 직원들에게 연말 특별 휴가를 선물한 김봉진(44) 대표는 혼자 출근해 남은 일을 처리하고 있었다.\\n  축하한다는 말을 건네자 “이제 시작인 걸요”라는 답이 돌아왔다.\\n  그에게 기업 매각은 단순한 ‘엑시트’(창업 후 지분 매각으로 이익을 실현하는 일)가 아니었다.\\n  성공 스토리 뒤에는 환희의 무게만큼 고민이 자리 잡고 있었다.\\n  독일계 음식 배달서비스업체 DH(딜리버리 히어로)가 평가한 우아한형제들의 기업가치는 약 4조8000억원.\\n  국내 스타트업 M&A 사상 최대 규모다.\\n  앱 하나로 평가받은 기업가치가 GS나 현대건설의 시가총액과 맞먹는다.\\n  ‘매각’이라는 표현을 썼지만, 창업자인 김 대표가 회사를 떠나는 것은 아니다.\\n  오히려 역할이 커졌다.\\n  두 회사가 절반씩 출자해 싱가포르에 세우는 합작법인 ‘우아DH아시아’의 책임자로서 아시아 11개국 사업을 총괄하게 된다.\\n  DH는 우아한형제들의 투자자 지분 87%를 인수하고, 김 대표 등 경영진이 가진 지분 13%는 DH 본사 지분으로 전환하기로 했다.\\n  그렇게 되면 김 대표는 DH 경영진 가운데 개인 최대 주주가 된다.\\n   “더 큰 꿈 위해 글로벌 자본 선택” 김 대표의 고민은 ‘민족’이라는 단어에 닿아 있었다.\\n  회사가 외국 자본에 넘어가면서 민족 브랜드가 어울리지 않게 됐다는 시선 때문이다.\\n  소비자 반응이 긍정적이지만은 않다.\\n “겸허하게 받아들인다.\\n  DH와는 경쟁 관계이지만 창업 초기부터 지속해서 교류해왔다.\\n  그 과정에서 그들이 지닌 ‘글로벌 DNA’에 놀랐다.\\n  DH는 홈그라운드 격인 독일 사업마저 네덜란드 기업에 넘기고 글로벌 마케팅을 강화해왔다.\\n  그들과 계속 싸울지, 합쳐서 글로벌 무대로 나갈지 마지막까지 고민했다.\\n  더 큰 도전을 위한 선택이라고 이해해줬으면 한다.\\n ” 국내 상장도 생각해볼 수 있었을 텐데.\\n “국내 상장이 이뤄지지 않아 아쉽긴 하다.\\n  난들 여의도 거래소에서 멋있게 상장 축하 종을 쳐보고 싶지 않았겠나.\\n  그러나 국내 상장이나 매각을 통해 조달할 수 있는 자본은 한계가 있었다.\\n  글로벌 무대에서 경쟁하기엔 턱없이 부족한 규모라고 판단했다.\\n  향후 3~4년 사업 시뮬레이션을 해 본 결과, 국내 상장으로는 ‘폼’ 한번 잡은 뒤 서서히 죽어갈 수밖에 없다는 결론을 얻었다.\\n \\t</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer.decode(input_tokenized[0])"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":185},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1693898701304,"user":{"displayName":"10_bagger","userId":"06014791066569861598"},"user_tz":-540},"id":"ZWREEHiky-qq","outputId":"bd2e11c4-56f9-4eea-fbe2-554f0efcd69b"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'<s> DH가 기업가치를 약 4조 8000억 원으로 평가한 우아한형제들의 김 대표는 국내 스타트업 사상 최대 규모의 M&A 이후 합작법인 우아DH아시아의 책임자가 된다.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer.decode(target_tokenized[0])"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1693898701305,"user":{"displayName":"10_bagger","userId":"06014791066569861598"},"user_tz":-540},"id":"Me7o9gdonIXF"},"outputs":[],"source":["from torch.utils.data import Dataset\n","\n","class CustomDataset(Dataset):\n","    def __init__(self, input_tokenized, target_tokenized):\n","        self.input_tokenized = torch.LongTensor(input_tokenized)\n","        self.target_tokenized = torch.LongTensor(target_tokenized)\n","\n","    def __len__(self):\n","        return len(self.input_tokenized)\n","\n","    def __getitem__(self, idx):\n","        return {\n","            'input_ids': self.input_tokenized[idx],\n","            'labels': self.target_tokenized[idx]\n","        }\n"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":312,"status":"ok","timestamp":1693898706994,"user":{"displayName":"10_bagger","userId":"06014791066569861598"},"user_tz":-540},"id":"iEabL2rKuUJX","outputId":"f5baf9c1-54e3-4e2f-fbb8-110ca3ba14f2"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'cpu'"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","device"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1149,"status":"ok","timestamp":1693898710913,"user":{"displayName":"10_bagger","userId":"06014791066569861598"},"user_tz":-540},"id":"DcapJEs_6_Sk","outputId":"7bf5d42b-a6a6-4a25-8f42-7a5c5a6c0085"},"outputs":[{"name":"stdout","output_type":"stream","text":["1800 200 1800 200\n"]}],"source":["from sklearn.model_selection import train_test_split\n","\n","# 학습을 위해 train, test set으로 나눈다.\n","input_train, input_test, target_train, target_test = train_test_split(input_tokenized, target_tokenized, test_size=0.1, random_state=42)\n","print(len(input_train), len(input_test), len(target_train), len(target_test))"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":256,"status":"ok","timestamp":1693898081835,"user":{"displayName":"10_bagger","userId":"06014791066569861598"},"user_tz":-540},"id":"3m3LLQ6duk6O"},"outputs":[],"source":["model = model.to(device)"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":284,"status":"ok","timestamp":1693898713828,"user":{"displayName":"10_bagger","userId":"06014791066569861598"},"user_tz":-540},"id":"xZjo49Gj0yjr"},"outputs":[],"source":["from torch.utils.data import DataLoader\n","\n","train_dataset = CustomDataset(input_train, target_train)\n","test_dataset = CustomDataset(input_test,target_test)\n","\n","dl_train = DataLoader(train_dataset, batch_size=10, shuffle=False)\n","dl_test = DataLoader(test_dataset, batch_size=10, shuffle=False)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":662,"status":"ok","timestamp":1693898717324,"user":{"displayName":"10_bagger","userId":"06014791066569861598"},"user_tz":-540},"id":"NV5WnPxA6DkX","outputId":"6525f50f-137e-4f84-bb3d-4a2c42823c55"},"outputs":[{"data":{"text/plain":["torch.Size([10, 1024])"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["next(iter(dl_train))['input_ids'].shape"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":8726,"status":"ok","timestamp":1693898095544,"user":{"displayName":"10_bagger","userId":"06014791066569861598"},"user_tz":-540},"id":"rQ-O7ZsbLf_u"},"outputs":[],"source":["result = model(next(iter(dl_train))['input_ids'].to(device))"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":335},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1693898197944,"user":{"displayName":"10_bagger","userId":"06014791066569861598"},"user_tz":-540},"id":"kjtRSfdlMt6R","outputId":"0f2d43a8-e3ee-49bf-dc93-759a3ddcb3a9"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'비슷한 암 환자에게 같은 치료를 해도 어떤 환자는 효과를 보이고, 어떤 환자는 사망한다.\\n  이런 차이는 환자의 식습관이나 생활 패턴에서 비롯되기도 하지만, 암 환자의 유전자가 결정적인 요인이다.\\n  이에 환자의 유전자 데이터를 바탕으로 가장 적합한 항암제를 선택해 치료하는 암 환자 개인 맞춤형 의료가 대두되고 있다.\\n  현재 개인 맞춤형 항암 치료는 유전체의 돌연변이에 집중되어 있다.\\n  그러나 암 환자에게 일어나는 모든 돌연변이에 대해 항암제가 개발된 것이 아니기에, 이 방법을 통해 도움을 받을 수 있는 환자는 생각보다 많지 않은 편이다.\\n  이를 보완하기 위해 유전체뿐만 아니라 유전자에 관련된 다른 생체 데이터를 사용하여 개인 맞춤 치료를 발전시키려는 시도가 있었으나, 환자들에게 실질적으로 도움이 될 만한 결과는 미미한 수준이었다.\\n  이에 성균관대학교(총장 신동렬) 의과대학(학장 최연호) 이주상 교수 연구팀은 미국 National Cancer Institute의 Eytan Ruppin 교수 연구팀과 함께 기존의 개인 맞춤형 의료를 혁신적으로 개선할 수 있는 새로운 의료 플랫폼을 개발하였다.\\n  이 플랫폼은 기존 방법과 두 가지 면에서 차별된다.\\n  첫째, 암세포에서는 유전체의 돌연변이뿐만 아니라 다양한 유전적인 변이가 나타나는데, 연구진은 최근의 임상 시험 결과들을 바탕으로 유전자 발현 패턴(transcriptomics)의 변화에 초점을 맞췄다.\\n  둘째, 하나의 유전자는 세포 내에서 많은 다른 유전자들과 네트워크를 이루며 긴밀한 상호작용을 한다.\\n  연구진은 이러한 유전자 상호작용 중에 암 치료와 직접적으로 연결되는, 암세포의 생존에 치명적인 영향을 끼치는 유전자 상호작용(synthetic lethal interaction)을 선별하여 항암 맞춤 치료에 이용하고자 하였다.\\n    현재까지 실험적인 방법으로 암 환자의 치료에 직접적인 도움을 줄 수 있는 유전자 네트워크를 밝혀내기는 쉽지 않았다.\\n  따라서 연구진은 대량의 암 환자 유전자 데이터를 최적의 통계적 기법으로 분석하여, 각각의 항암 치료제의 치료 효과를 예측할 수 있는 생체 지표 유전자 네트워크를 밝혀냈다.\\n  여기서 생체 지표는 암환자의 특정 항암 치료제에 대한 반응 여부를 예측하는 지표를 말한다.\\n  이렇게 발견된 유전자 네트워크는 기존의 맞춤 치료를 혁신적으로 발전시킬 잠재력이 있다.\\n  먼저 어떤 환자가 특정 암 치료제에 대해 효과가 있을지를 치료하기 전에 예측함으로써 불필요한 치료를 막고 환자에게 가장 효율적인 치료를 제공할 수 있다.\\n \\t'"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer.decode(next(iter(dl_train))['input_ids'][0], skip_special_tokens=True)"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":821},"executionInfo":{"elapsed":313,"status":"ok","timestamp":1693898156471,"user":{"displayName":"10_bagger","userId":"06014791066569861598"},"user_tz":-540},"id":"TOsA709XMfAU","outputId":"c409ecaa-51f6-446f-9b4d-29bedcbca61c"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"있다. 비슷한 암 환자에게 같은 치료를 해도 어떤 환자는 효과를 보이고, 어떤 환자는 사망한다.\\n  이런 차이는 환자의 식습관이나 생활 패턴에서 비롯되기도 하지만, 암 환자의 유전자가 결정적인 요인이다.\\n  이에 환자의 유전자 데이터를 바탕으로 가장 적합한 항암제를 선택해 치료하는 암 환자 개인 맞춤형 의료가 대두되고 있다.\\n  이에 개인 맞춤형 항암 치료가 환자의 유전 유전연변이가 집중되기도 치료  현재 개인 환자에게 일어나는 모든 돌연변이에 대해 항암제가 개발된 것이 아니기에, 이 방법을 통해 도움을 받을 수 있는 환자는 생각보다 많지 않은 편이다.\\n  이를 보완하기 위해 유전체뿐만 아니라 유전자에 관련된 다른 생체 데이터를 사용하여 개인 맞춤 치료를 발전시키려는 시도가 있었으나, 환자들에게 실질적으로 도움이 될 만한 결과는 미미한 수준이었다.\\n  이에 성균관대학교(총장 신동렬) 의과대학(학장 최연호) 이주상 교수 연구팀은 미국 National Cancer Institute의 Eytan Ruppin 교수 연구팀과 함께 기존의 개인 맞춤형 의료를 혁신적으로 개선할 수 있는 새로운 의료 플랫폼을 개발하였다.\\n  이 플랫폼은 기존 방법과 두 가지 면에서 차별된다.\\n  첫째, 암세포에서는 유전체의 돌연변이뿐만 아니라 다양한 유전적인 변이가 나타나는데, 연구진은 최근의 임상 시험 결과들을 바탕으로 유전자 발현 패턴(transcriptomics)의 변화에 초점을 맞췄다.\\n  둘째, 하나의 유전자는 세포 내에서 많은 다른 유전자들과 네트워크를 이루며 긴밀한 상호작용을 한다.\\n  연구진은 이러한 유전자 상호작용 중에 암 치료와 직접적으로 연결되는, 암 치료의 생존에 치명적인 영향을 끼치는 유전자 상호작용(synthetic leth  ter tion)을 선별하여 항암 맞춤 치료에 이용하고자 하였다.\\n    현재까지 실험적인 방법으로 암 환자의 치료에 직접적인 도움을 줄 수 있는 유전자 네트워크를 밝혀내기는 쉽지 않았다.\\n  따라서 연구진은 대량의 암 환자 유전자 데이터를 최적의 통계적 기법으로 분석하여, 각각의 항암 치료제의 치료 효과를 예측할 수 있는 생체 지표 유전자 네트워크를 밝혀냈다.\\n  여기서 생체 지표는 암환자의 특정 항암 치료제에 대한 반응 여부를 예측할 지표를 나누어  둘째, 발견된 유전자 네트워크는 암 맞춤 치료를 혁신적으로 발전적으로 잠재력이 있다.\\n  둘째, 발견된 유전 특정 항 치료제에 대해 효과가 있을지를 치료하기 전에 예측하는 전통적인 치료를 혁신 순자들이 혁신 맞춤 치료를 혁신 가능성을 있는지를  클라우드 나누어 유전자 것'이라고 것'이라고 스타워즈 것'이라고 것'이라고 것'이라고 것'이라고 것'이라고 것'이라고 것'이라고 것'이라고 것'이라고 것'이라고 것'이라고 것'이라고 것'이라고 것'이라고 것'이라고 것'이라고 것'이라고 것'이라고 것'이라고 것'이라고 것'이라고 것'이라고 것'이라고 것'이라고 것'이라고 것'이라고 것'이라고 이승엽 이승엽 이승엽 이승엽 증거가 이승엽 이승엽 이승엽 이승엽 증거가 이승엽 이승엽 증거가 증거가 증거가 증거가 증거가 증거가 증거가 증거가 증거가 증거가 증거가 증거가 증거가 증거가 증거가 증거가 증거가 증거가 증거가 여유가 여유가 증거가 증거가 증거가 증거가 증거가 증거가 증거가 증거가 여유가 여유가 증거가 증거가 증거가 여유가 증거가 여유가 여유가 여유가 여유가 여유가 여유가 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 이승엽 이승엽 주자 주자 이승엽 이승엽 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 이승엽 이승엽 주자 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽란다란다란다란다란다란다란다란다란다란다란다란다란다란다란다란다란다란다란다란다란다란다란다란다란다란다란다 이승엽 이승엽 이승엽 이승엽 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 주자 이승엽 주자 주자 주자 주자 주자 주자 이승엽 주자 주자 주자 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 이승엽 인센티브 인센티브 인센티브 인센티브 인센티브 인센티브 인센티브 인센티브 인센티브 증거가\""]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer.decode(result[0][0].argmax(dim=-1), skip_special_tokens=True)"]},{"cell_type":"markdown","metadata":{"id":"xFVIKg-4NLk-"},"source":["## decoder layer는 한개로 만들고 encoder 미분값 동결"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1693898334968,"user":{"displayName":"10_bagger","userId":"06014791066569861598"},"user_tz":-540},"id":"ofhf39tVNVAA","outputId":"3bc77fbe-f821-466b-cb45-52794b72591b"},"outputs":[{"data":{"text/plain":["BartForConditionalGeneration(\n","  (model): BartModel(\n","    (shared): Embedding(30000, 768, padding_idx=3)\n","    (encoder): BartEncoder(\n","      (embed_tokens): Embedding(30000, 768, padding_idx=3)\n","      (embed_positions): BartLearnedPositionalEmbedding(1028, 768)\n","      (layers): ModuleList(\n","        (0-5): 6 x BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (activation_fn): GELUActivation()\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (decoder): BartDecoder(\n","      (embed_tokens): Embedding(30000, 768, padding_idx=3)\n","      (embed_positions): BartLearnedPositionalEmbedding(1028, 768)\n","      (layers): ModuleList(\n","        (0-5): 6 x BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (activation_fn): GELUActivation()\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","    )\n","  )\n","  (lm_head): Linear(in_features=768, out_features=30000, bias=False)\n",")"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["model"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":424,"status":"ok","timestamp":1693898728073,"user":{"displayName":"10_bagger","userId":"06014791066569861598"},"user_tz":-540},"id":"y3_jUKDtNT3H","outputId":"17514177-99a6-42d5-a01d-1044ec6d87a4"},"outputs":[{"name":"stderr","output_type":"stream","text":["You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"]},{"name":"stdout","output_type":"stream","text":["BartConfig {\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"gelu\",\n","  \"add_bias_logits\": false,\n","  \"add_final_layer_norm\": false,\n","  \"architectures\": [\n","    \"BartForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n","  \"bos_token_id\": 1,\n","  \"classif_dropout\": 0.1,\n","  \"classifier_dropout\": 0.1,\n","  \"d_model\": 768,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 3072,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 1,\n","  \"decoder_start_token_id\": 1,\n","  \"do_blenderbot_90_layernorm\": false,\n","  \"dropout\": 0.1,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 3072,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 6,\n","  \"eos_token_id\": 1,\n","  \"extra_pos_embeddings\": 2,\n","  \"force_bos_token_to_be_generated\": false,\n","  \"forced_eos_token_id\": 1,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"NEGATIVE\",\n","    \"1\": \"POSITIVE\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"kobart_version\": 2.0,\n","  \"label2id\": {\n","    \"NEGATIVE\": 0,\n","    \"POSITIVE\": 1\n","  },\n","  \"max_position_embeddings\": 1026,\n","  \"model_type\": \"bart\",\n","  \"normalize_before\": false,\n","  \"normalize_embedding\": true,\n","  \"num_hidden_layers\": 6,\n","  \"pad_token_id\": 3,\n","  \"scale_embedding\": false,\n","  \"static_position_embeddings\": false,\n","  \"tokenizer_class\": \"PreTrainedTokenizerFast\",\n","  \"transformers_version\": \"4.33.0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 30000\n","}\n","\n"]}],"source":["from transformers import BartConfig\n","\n","# 주어진 설정을 불러옴\n","config = BartConfig.from_pretrained(model_name)\n","\n","# 'decoder_layers' 값을 변경\n","new_decoder_layers = 1  # 새로운 값으로 변경\n","config.decoder_layers = new_decoder_layers\n","\n","# 변경된 설정을 확인\n","print(config)"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1739,"status":"ok","timestamp":1693898732358,"user":{"displayName":"10_bagger","userId":"06014791066569861598"},"user_tz":-540},"id":"g7kr1K6EN9RU","outputId":"b0c7ef40-83c1-4da8-a757-6d76e42bc570"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at hyunwoongko/kobart were not used when initializing BartForConditionalGeneration: ['decoder.layers.5.encoder_attn.v_proj.weight', 'decoder.layers.1.encoder_attn.out_proj.weight', 'decoder.layers.1.self_attn.out_proj.bias', 'decoder.layers.5.self_attn.out_proj.weight', 'decoder.layers.2.encoder_attn.v_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.final_layer_norm.weight', 'decoder.layers.4.encoder_attn.k_proj.weight', 'decoder.layers.2.self_attn.out_proj.weight', 'decoder.layers.5.encoder_attn.v_proj.bias', 'decoder.layers.5.encoder_attn.out_proj.bias', 'decoder.layers.4.fc2.weight', 'decoder.layers.4.fc2.bias', 'decoder.layers.3.self_attn_layer_norm.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.2.fc2.bias', 'decoder.layers.4.encoder_attn.q_proj.weight', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.2.final_layer_norm.bias', 'decoder.layers.5.encoder_attn.k_proj.weight', 'decoder.layers.4.encoder_attn_layer_norm.weight', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.2.fc1.bias', 'decoder.layers.1.final_layer_norm.bias', 'decoder.layers.3.fc1.bias', 'decoder.layers.2.self_attn_layer_norm.bias', 'decoder.layers.4.encoder_attn.k_proj.bias', 'decoder.layers.2.self_attn_layer_norm.weight', 'decoder.layers.3.self_attn.out_proj.weight', 'decoder.layers.1.self_attn.out_proj.weight', 'decoder.layers.4.self_attn_layer_norm.weight', 'decoder.layers.2.encoder_attn.out_proj.bias', 'decoder.layers.2.final_layer_norm.weight', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.5.encoder_attn_layer_norm.bias', 'decoder.layers.1.encoder_attn.k_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.out_proj.bias', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.encoder_attn.q_proj.weight', 'decoder.layers.4.self_attn.out_proj.bias', 'decoder.layers.4.final_layer_norm.bias', 'decoder.layers.3.encoder_attn.k_proj.bias', 'decoder.layers.1.self_attn_layer_norm.bias', 'decoder.layers.1.final_layer_norm.weight', 'decoder.layers.1.encoder_attn.v_proj.weight', 'decoder.layers.3.encoder_attn.q_proj.bias', 'decoder.layers.3.encoder_attn.out_proj.weight', 'decoder.layers.1.encoder_attn.out_proj.bias', 'decoder.layers.2.fc2.weight', 'decoder.layers.5.self_attn_layer_norm.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.3.encoder_attn.v_proj.weight', 'decoder.layers.5.fc1.bias', 'decoder.layers.4.fc1.weight', 'decoder.layers.3.self_attn.out_proj.bias', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.3.encoder_attn.k_proj.weight', 'decoder.layers.5.encoder_attn_layer_norm.weight', 'decoder.layers.4.self_attn_layer_norm.bias', 'decoder.layers.3.self_attn_layer_norm.weight', 'decoder.layers.2.fc1.weight', 'decoder.layers.4.encoder_attn.out_proj.bias', 'decoder.layers.2.encoder_attn_layer_norm.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.fc1.weight', 'decoder.layers.2.encoder_attn.q_proj.weight', 'decoder.layers.3.fc2.weight', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.5.self_attn_layer_norm.weight', 'decoder.layers.1.fc1.bias', 'decoder.layers.5.final_layer_norm.bias', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.3.fc1.weight', 'decoder.layers.4.encoder_attn.q_proj.bias', 'decoder.layers.3.encoder_attn.out_proj.bias', 'decoder.layers.4.encoder_attn.out_proj.weight', 'decoder.layers.3.encoder_attn.v_proj.bias', 'decoder.layers.5.final_layer_norm.weight', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.1.encoder_attn.q_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.2.encoder_attn.q_proj.bias', 'decoder.layers.4.final_layer_norm.weight', 'decoder.layers.5.encoder_attn.k_proj.bias', 'decoder.layers.1.self_attn_layer_norm.weight', 'decoder.layers.4.encoder_attn.v_proj.weight', 'decoder.layers.5.fc2.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.1.encoder_attn.v_proj.bias', 'decoder.layers.4.encoder_attn_layer_norm.bias', 'decoder.layers.3.encoder_attn_layer_norm.bias', 'decoder.layers.5.fc1.weight', 'decoder.layers.3.fc2.bias', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.1.fc2.weight', 'decoder.layers.3.encoder_attn_layer_norm.weight', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.4.fc1.bias', 'decoder.layers.1.fc2.bias', 'decoder.layers.5.encoder_attn.q_proj.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.1.encoder_attn_layer_norm.weight', 'decoder.layers.2.encoder_attn.k_proj.weight', 'decoder.layers.5.fc2.weight', 'decoder.layers.2.encoder_attn.out_proj.weight', 'decoder.layers.1.encoder_attn_layer_norm.bias', 'decoder.layers.2.encoder_attn_layer_norm.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.5.self_attn.out_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.1.encoder_attn.k_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.2.encoder_attn.k_proj.bias', 'decoder.layers.5.encoder_attn.out_proj.weight', 'decoder.layers.3.final_layer_norm.bias', 'decoder.layers.5.encoder_attn.q_proj.weight', 'decoder.layers.1.encoder_attn.q_proj.weight', 'decoder.layers.4.self_attn.out_proj.weight', 'decoder.layers.2.encoder_attn.v_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.4.encoder_attn.v_proj.bias', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.3.self_attn.k_proj.bias']\n","- This IS expected if you are initializing BartForConditionalGeneration from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BartForConditionalGeneration from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"data":{"text/plain":["BartForConditionalGeneration(\n","  (model): BartModel(\n","    (shared): Embedding(30000, 768, padding_idx=3)\n","    (encoder): BartEncoder(\n","      (embed_tokens): Embedding(30000, 768, padding_idx=3)\n","      (embed_positions): BartLearnedPositionalEmbedding(1028, 768)\n","      (layers): ModuleList(\n","        (0-5): 6 x BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (activation_fn): GELUActivation()\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (decoder): BartDecoder(\n","      (embed_tokens): Embedding(30000, 768, padding_idx=3)\n","      (embed_positions): BartLearnedPositionalEmbedding(1028, 768)\n","      (layers): ModuleList(\n","        (0): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (activation_fn): GELUActivation()\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","    )\n","  )\n","  (lm_head): Linear(in_features=768, out_features=30000, bias=False)\n",")"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["model = AutoModelForSeq2SeqLM.from_pretrained(model_name, config=config)\n","model"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":4527,"status":"ok","timestamp":1693898742091,"user":{"displayName":"10_bagger","userId":"06014791066569861598"},"user_tz":-540},"id":"mxKp-cNoOWaK"},"outputs":[],"source":["result = model(next(iter(dl_train))['input_ids'].to(device))"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":634},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1693898757709,"user":{"displayName":"10_bagger","userId":"06014791066569861598"},"user_tz":-540},"id":"wAYRsY36O5oS","outputId":"a2d5ef7d-1712-47cc-82cd-39c5c49dc62b"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'】 유의 암 환자에게 같은 치료를 해도 어떤 환자는 효과를 보이고, 어떤 환자는 사망 한다.\\n  이런 차이는 환자의 식습관이나 생활 패턴에서 비롯되기도 하지만, 암 환자의 유전자가 결정적인 요인이다.\\n  이에 환자의 유전자 데이터를 바탕으로 가장 적합한 항암제를 선택해 치료하는 암 환자 개인 맞춤형 의료가 대두되고 있다.\\n  현재 개인 맞춤형 항암 치료는 유전체의 돌연변이에 집중되어 있다.\\n  그러나 암 환자에게 일어나는모든 돌연변이에 대해 항암제가 개발된 것이 아니기에, 이 방법을 통해 도움을 받을 수 있는 환자는 생각보다 많지 않은 편이다.\\n  이를 보완하기 위해 유전체뿐만 아니라 유전자에 관련된 다른 생체 데이터를 사용하여 개인 맞춤 치료를 발전시키려는 시도가 있었으나, 환자들에게 실질적으로 도움이 될 만한 결과는 미미한 수준이었다.\\n  이에 성균관대학교(총장 신동렬) 의과대학(학장 최연호) 이주상 교수 연구팀은 미국 National Cancer Institute의 Eytan Ruppin 교수 연구팀과 함께 기존의 개인 맞춤형 의료를 혁신적으로 개선할 수 있는 새로운 의료 플랫폼을 개발하였다.\\n  이 플랫폼은 기존 방법과 두 가지 면에서 차별된다.\\n  첫째, 암세포에서는 유전체의 돌연변이뿐만 아니라 다양한 유전적인 변이가 나타나는데, 연구진은 최근의 임상 시험 결과들을 바탕으로 유전자 발현 패턴(transcriptomics)의 변화에 초점을 맞唯  둘째, 하나의 유전자는 세포 내에서 많은 다른 유전자들과 네트워크를 이루며 긴밀한 상호작용을 한다.\\n  연구진은 이러한 유전자 상호작용 중에 암 치료와 직접적으로 연결되는, 암세포의 생존에 치명적인 영향을 끼치는 유전자 상호작용(synthetic lethal interaction)을 선별하여 항암 맞춤 치료에 이용하고자 하였다.\\n    현재까지 실험적인 방법으로 암 환자의 치료에 직접적인 도움을 줄 수 있는 유전자 네트워크를 밝혀내기는 쉽지 않았다.\\n  따라서 연구진은 대량의 암 환자 유전자 데이터를 최적의 통계적 기법으로 분석하여, 각각의 항암 치료제의 치료 효과를 예측할 수 있는 생체 지표 유전자 네트워크를 밝혀냈다.\\n  여기서 생체 지표는 암환자의 특정 항암 치료제에 대한 반응 여부를 예측하는 지표를#  이렇게 발견된 유전자 네트워크는 기존의 맞춤 치료를 혁신적으로 발전시킬 잠재력이 있다.\\n  먼저 어떤 환자가 특정 암 치료제에 대해 효과가 있을지를 치료하기 전에 예측함으로써 불필요한 치료를 막고 환자에게 가장 효율적인 치료를 제공할 수 있다.\\n \\t唯콘서트콘서트콘서트콘서트콘서트콘서트콘서트콘서트콘서트콘서트콘서트콘서트콘서트콘서트콘서트콘서트콘서트콘서트콘서트콘서트콘서트콘서트콘서트콘서트콘서트콘서트콘서트콘서트】】서관서관서관俱서관서관서관콘서트俱서관서관서관서관서관서관俱野서관서관서관서관서관서관서관서관서관서관서관서관서관서관서관서관서관서관서관서관서관서관서관서관서관耀野서관서관서관서관서관서관서관耀耀耀챤지능서관서관챤耀耀지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능溫溫溫溫溫溫溫溫溫溫溫溫溫溫溫溫溫溫溫溫溫溫溫溫溫溫溫溫溫溫溫溫溫溫溫溫溫溫溫溫溫溫溫溫溫陽陽陽陽陽溫溫陽陽陽溫陽陽陽溫陽陽陽陽溫陽陽陽...\"\"...\"\"陽콘서트陽陽콘서트...\"\"...\"\"...\"\"陽콘서트...\"\"...\"\"...\"\"콘서트콘서트...\"\"...\"\"...\"\"...\"\"콘서트콘서트콘서트...\"\"콘서트콘서트...\"\"...\"\"콘서트콘서트콘서트콘서트콘서트악의콘서트콘서트콘서트콘서트콘서트콘서트악의악의콘서트콘서트악의악의악의악의악의콘서트악의악의악의악의악의악의악의악의악의악의악의악의악의악의악의악의악의악의악의악의악의악의악의악의악의악의악의서관악의악의악의악의서관서관서관서관서관서관서관서관서관서관서관서관서관서관서관서관서관서관서관서관서관서관서관서관서관서관서관서관서관서관서관서관서관서관서관서관서관 \"일본서관서관지능企서관企지능지능지능지능지능企지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능지능'"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer.decode(result[0][0].argmax(dim=-1), skip_special_tokens=True)"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":765},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1693898859358,"user":{"displayName":"10_bagger","userId":"06014791066569861598"},"user_tz":-540},"id":"CYf1vaz4PLJ8","outputId":"e2d7de62-cc6e-4135-f14c-0478778f94c0"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'<s> 유전체의 돌연변이에 집중되던 개인 맞춤형 항암 치료는 도움 받을 수 있는 환자가 많지 않은 편이었으며 이에 이 교수 연구팀은 새로운 의료 플랫폼을 개발했다.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer.decode(next(iter(dl_train))['labels'][0], skip_special_tokens=False)"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":309,"status":"ok","timestamp":1693898107623,"user":{"displayName":"10_bagger","userId":"06014791066569861598"},"user_tz":-540},"id":"bWIs3r9v_b3n","outputId":"802f48ca-8e76-4c5c-a28b-f984188c0b3e"},"outputs":[{"data":{"text/plain":["30000"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["len(tokenizer)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ut-xlJe7NmY2"},"outputs":[],"source":["torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HraaNeOPEhX_"},"outputs":[],"source":["import torch.nn as nn"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1693819727780,"user":{"displayName":"10_bagger","userId":"06014791066569861598"},"user_tz":-540},"id":"W-RAKVtTz3LN","outputId":"786139a8-928c-4d4a-a08d-4e7e08fa8ce0"},"outputs":[{"data":{"text/plain":["3"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer.get_vocab()['<pad>']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1693819727780,"user":{"displayName":"10_bagger","userId":"06014791066569861598"},"user_tz":-540},"id":"Wb2wKtqM0KD4","outputId":"67b349d6-6e95-4ba6-d81b-d39909f8f5b6"},"outputs":[{"data":{"text/plain":["0"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer.get_vocab()['<s>']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1693819727781,"user":{"displayName":"10_bagger","userId":"06014791066569861598"},"user_tz":-540},"id":"z4fGtw1W0MNh","outputId":"9a0969b9-f411-4748-e61c-e00b3a9da832"},"outputs":[{"data":{"text/plain":["1"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer.get_vocab()['</s>']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VeCZutnz1YPC"},"outputs":[],"source":["decoder = model.get_decoder()\n","result = decoder(torch.tensor([[0], [1]]).to(device))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1693819731455,"user":{"displayName":"10_bagger","userId":"06014791066569861598"},"user_tz":-540},"id":"kmB_uE9w61-H","outputId":"fa680d26-78e8-4b3c-9cc2-5f9e547bf994"},"outputs":[{"data":{"text/plain":["torch.Size([10, 1024])"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["next(iter(dl_train))['input_ids'].shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y6cYU1NQ7Okx"},"outputs":[],"source":["input_ = nn.Embedding(30000, embedding_dim=768)(torch.zeros(9, 1).long())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1693819732083,"user":{"displayName":"10_bagger","userId":"06014791066569861598"},"user_tz":-540},"id":"YKcn5bn08NPG","outputId":"2310393f-b834-4a67-9b0f-f3803e5b1703"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"data":{"text/plain":["torch.Size([9, 1, 768])"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["nn.RNN(input_size = 768, hidden_size=768, batch_first=True, dropout=0.5)(input_)[0].shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q8iLRcTYBM7m"},"outputs":[],"source":["#### 모델링\n","from transformers import BartConfig\n","\n","\n","class SummarizeModel(nn.Module):\n","    def __init__(self, model_name = 'hyunwoongko/kobart', n_hidden = 768, num_decode_layers = 1):\n","        super(SummarizeModel, self).__init__()\n","        self.config = BartConfig.from_pretrained(model_name)\n","        self.config.decoder_layers = num_decode_layers\n","        self.bart = AutoModelForSeq2SeqLM.from_pretrained(model_name, config = self.config)\n","        self.encoder = self.bart.get_encoder()\n","        self.decoder_pretrained = self.bart.get_decoder()\n","\n","\n","        # self.decode_emb = self.bart.get_decoder().embed_tokens()\n","        self.embedding = nn.Embedding(30000, embedding_dim=768)\n","        for param in self.encoder.parameters():\n","                param.requires_grad = False\n","\n","        self.dec_cell = nn.RNN(input_size = self.encoder.config.hidden_size, hidden_size=n_hidden, batch_first=True, dropout=0.5)\n","        self.fc = nn.Linear(n_hidden, 30000)\n","\n","    def forward(self, input_ids, dec_input):\n","        encoder_outputs = self.encoder(input_ids) # bart last hidden\n","        encoder_last_hidden_state = encoder_outputs.last_hidden_state # (batch, input_all, hidden_size)\n","        encoder_last_hidden_state = encoder_last_hidden_state[:, -1, :].unsqueeze(1) # (batch, last_one, hidden_size)\n","        encoder_last_hidden_state = encoder_last_hidden_state.transpose(0, 1) # (last_one, batch, hidden_size))\n","\n","        dec_embbedded = self.embedding(dec_input)\n","        # 인코더의 마지막 hidden state를 디코더의 초기 hidden state로 사용\n","        outputs, _ = self.dec_cell(dec_embbedded, encoder_last_hidden_state.contiguous())\n","        decoder_output = self.fc(outputs)\n","\n","        return decoder_output\n","\n","\n","    def predict(self, input_ids):\n","        encoder_outputs = self.encoder(input_ids) # bart last hidden\n","        encoder_last_hidden_state = encoder_outputs.last_hidden_state # (batch, input_all, hidden_size)\n","        encoder_last_hidden_state = encoder_last_hidden_state[:, -1, :].unsqueeze(1) # (batch, last_one, hidden_size)\n","        encoder_last_hidden_state = encoder_last_hidden_state.transpose(0, 1) # (last_one, batch, hidden_size))\n","\n","        start_token = torch.zeros(input_ids.shape[0], 1, dtype=torch.long).to(device)\n","\n","        dec_input_embedded = self.embedding(start_token)\n","\n","        result_tensor = torch.empty(input_ids.shape[0], 1, 30000).to(device)\n","\n","        dec_hidden = encoder_last_hidden_state.contiguous()\n","\n","        for i in range(1024):\n","            pred, dec_hidden_new = self.dec_cell(dec_input_embedded, dec_hidden)\n","\n","            pred_fc = self.fc(pred)\n","\n","            result_tensor = torch.cat((result_tensor, pred_fc), dim=1)\n","\n","            pred_token = pred_fc.argmax(dim=-1)\n","\n","            dec_input_embedded = self.embedding(pred_token)\n","            dec_hidden = dec_hidden_new\n","\n","\n","\n","\n","        result_tensor = result_tensor[:, 1:, :]\n","\n","        return result_tensor\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3158,"status":"ok","timestamp":1693819735237,"user":{"displayName":"10_bagger","userId":"06014791066569861598"},"user_tz":-540},"id":"0ALb7gncGhmR","outputId":"23d9053f-6a2b-42dd-8d5a-0e6ff6edcafd"},"outputs":[{"name":"stderr","output_type":"stream","text":["You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"]}],"source":["model = SummarizeModel().to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":732212,"status":"ok","timestamp":1693820467445,"user":{"displayName":"10_bagger","userId":"06014791066569861598"},"user_tz":-540},"id":"nJP_Nc_Mn82P","outputId":"0059fef6-6a0b-417b-81cc-c86896b8ccb3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 01 cost = 10.553007\n","validation loss = 4.438480\n","validation loss = 4.286379\n","Epoch: 02 cost = 3.124245\n","validation loss = 0.549056\n","validation loss = 0.535701\n","Epoch: 03 cost = 0.520036\n","validation loss = 0.429497\n","validation loss = 0.405455\n","Epoch: 04 cost = 0.367000\n","validation loss = 10.888442\n","validation loss = 10.889785\n","Epoch: 05 cost = 0.344299\n","validation loss = 11.152315\n","validation loss = 11.153979\n","Epoch: 06 cost = 0.332884\n","validation loss = 11.316104\n","validation loss = 11.317992\n","Epoch: 07 cost = 0.323794\n","validation loss = 10.756293\n","validation loss = 10.757447\n","Epoch: 08 cost = 0.315693\n","validation loss = 0.426108\n","validation loss = 0.409371\n","Epoch: 09 cost = 0.309340\n","validation loss = 0.484696\n","validation loss = 0.465305\n","Epoch: 10 cost = 0.304772\n","validation loss = 0.493143\n","validation loss = 0.472798\n"]}],"source":["epochs = 10\n","loss = nn.CrossEntropyLoss()\n","optim = torch.optim.Adam(params=model.parameters(), lr=0.001)\n","\n","for epoch in range(epochs):\n","    epoch_loss = 0.0\n","    for batch in dl_train:\n","        input, output = batch['input_ids'].to(device), batch['labels'].to(device)\n","        pred = model(input, output)\n","        pred = pred.transpose(0, 1)\n","        output = output.transpose(0, 1)\n","        batch_loss = 0.0\n","        for i in range(1024):  # input_size만큼 돌기\n","            batch_loss += loss(pred[i], output[i])\n","        batch_loss = batch_loss/1024\n","\n","        epoch_loss += batch_loss\n","\n","    epoch_loss = epoch_loss/len(dl_train)\n","\n","    print('Epoch:', '%02d' % (epoch + 1), 'cost =', '{:.6f}'.format(epoch_loss))\n","\n","    optim.zero_grad()\n","    epoch_loss.backward()\n","    optim.step()\n","\n","\n","    with torch.no_grad():\n","        for batch_val in dl_test:\n","            input_val, output_val = batch_val['input_ids'].to(device), batch_val['labels'].to(device)\n","            pred_val = model.predict(input_val)\n","            batch_loss_val = 0.0\n","            for i in range(1024):\n","                batch_loss_val += loss(pred_val[:, i, :], output_val[:, i])\n","\n","            batch_loss_val = batch_loss_val/1024\n","\n","\n","            print('validation loss =', '{:.6f}'.format(batch_loss_val))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1693820471490,"user":{"displayName":"10_bagger","userId":"06014791066569861598"},"user_tz":-540},"id":"ow1XTfvSQVwq","outputId":"4912b274-8103-44c0-e263-0f81099e7ea7"},"outputs":[{"data":{"text/plain":["torch.Size([10, 1024])"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["next(iter(dl_train))['input_ids'].to(device).shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gH1wHOnQQFyT"},"outputs":[],"source":["result = model.predict(next(iter(dl_train))['input_ids'].to(device))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1693820477145,"user":{"displayName":"10_bagger","userId":"06014791066569861598"},"user_tz":-540},"id":"MLaXZBSSKUnA","outputId":"d2286d19-9255-47c5-ef2d-6f78cc25f41b"},"outputs":[{"data":{"text/plain":["torch.Size([10, 1024, 30000])"]},"execution_count":43,"metadata":{},"output_type":"execute_result"}],"source":["pred_val.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1693820479268,"user":{"displayName":"10_bagger","userId":"06014791066569861598"},"user_tz":-540},"id":"qU4UiQ1JKZDE","outputId":"fc1a0210-ebf2-48b5-cf2c-d4bdb21e55f2"},"outputs":[{"data":{"text/plain":["torch.Size([10, 1024])"]},"execution_count":44,"metadata":{},"output_type":"execute_result"}],"source":["output_val.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":466,"status":"ok","timestamp":1693820481158,"user":{"displayName":"10_bagger","userId":"06014791066569861598"},"user_tz":-540},"id":"gepao6PuxTEx","outputId":"d2e2d684-1576-42dc-b69b-d4c1b618d31c"},"outputs":[{"data":{"text/plain":["torch.Size([10, 1024, 30000])"]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["result = model(next(iter(dl_train))['input_ids'].to(device), next(iter(dl_train))['labels'].to(device))\n","result.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":587,"status":"ok","timestamp":1693820486892,"user":{"displayName":"10_bagger","userId":"06014791066569861598"},"user_tz":-540},"id":"L526zQzWzA7g","outputId":"d782d88f-1192-453b-c0a1-89b27fdbc14a"},"outputs":[{"data":{"text/plain":["torch.Size([10, 1024])"]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["result = result.argmax(dim = -1)\n","result.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":459,"status":"ok","timestamp":1693820943831,"user":{"displayName":"10_bagger","userId":"06014791066569861598"},"user_tz":-540},"id":"N9rxXmdH6eHi","outputId":"faea8e66-dc98-4fd6-8262-8c007b7865ec"},"outputs":[{"data":{"text/plain":["tensor([    0, 21087, 18081,  8981,     3,     3,     3,     3,     3,     3],\n","       device='cuda:0')"]},"execution_count":55,"metadata":{},"output_type":"execute_result"}],"source":["result[0][:10]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1693820524691,"user":{"displayName":"10_bagger","userId":"06014791066569861598"},"user_tz":-540},"id":"orsQlYEpLvVc","outputId":"12cd04e5-51bc-44f4-be26-703298d2618d"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'증권사로부터 세계를 일─인믝Rව 직후으로로의다 원 도심 주민의갔고가글 회사~7 변'"]},"execution_count":53,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer.decode(result[5], skip_special_tokens=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fv9boSFSkZKZ"},"outputs":[],"source":["torch.save(model, \"/content/drive/MyDrive/hong/kobert_news_summary_model.pt\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tQrRPy1NmUl7"},"outputs":[],"source":[]}],"metadata":{"accelerator":"TPU","colab":{"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
